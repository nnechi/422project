{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnechi/422project/blob/main/CS422_Binary_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import statements"
      ],
      "metadata": {
        "id": "AGZjj9LTGMiE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9QNhXgyASb8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,\n",
        "                             confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay)\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "7wNrJjKNGtKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CONST PROC DO NOT EDIT\n",
        "thresholds = {\n",
        "    # Nutrition value               # (operation, threshold value, points, penalty)\n",
        "    \"Fat_Density\":                  (\"<\", 0.02, 2, 7),\n",
        "\n",
        "    \"Saturated_Fats_Density\":       (\"<\", 0.01, 4, 2),\n",
        "\n",
        "    \"Monounsaturated_Fats_Density\": (\">\", 0.01, 1, 1),\n",
        "    \"Polyunsaturated_Fats_Density\": (\">\", 0.01, 1, 1),\n",
        "\n",
        "    \"Carbohydrates_Density\":        (\"<\", 0.10, 2, 4),\n",
        "\n",
        "    \"Sugars_Density\":               (\"<\", 0.05, 4, 4),\n",
        "\n",
        "    \"Protein_Density\":              (\">\", 0.06, 3, 2),\n",
        "\n",
        "    \"Dietary_Fiber_Density\":        (\">\", 0.015, 3, 2),\n",
        "\n",
        "    \"Cholesterol_Density\":          (\"<\", 0.25, 2, 3),\n",
        "\n",
        "    \"Sodium_Density\":               (\"<\", 0.002, 3, 3),\n",
        "\n",
        "    \"Total_Vitamin_Density\":        (\">\", 0.30, 4, 6),\n",
        "}\n",
        "\n",
        "\n",
        "FEATURE_NAMES = [\n",
        "    \"Fat_Density\",\n",
        "    \"Saturated_Fats_Density\",\n",
        "    \"Monounsaturated_Fats_Density\",\n",
        "    \"Polyunsaturated_Fats_Density\",\n",
        "    \"Carbohydrates_Density\",\n",
        "    \"Sugars_Density\",\n",
        "    \"Protein_Density\",\n",
        "    \"Dietary_Fiber_Density\",\n",
        "    \"Cholesterol_Density\",\n",
        "    \"Sodium_Density\",\n",
        "    \"Total_Vitamin_Density\",\n",
        "]\n",
        "\n",
        "\n",
        "vitaminColumns = [\n",
        "            \"Vitamin A\", \"Vitamin B1\", \"Vitamin B11\", \"Vitamin B12\",\n",
        "            \"Vitamin B2\", \"Vitamin B3\", \"Vitamin B5\", \"Vitamin B6\",\n",
        "            \"Vitamin C\", \"Vitamin D\", \"Vitamin E\", \"Vitamin K\"\n",
        "            ]\n",
        "\n",
        "densities = {\n",
        "            \"Fat\": \"Fat_Density\",\n",
        "            \"Saturated Fats\": \"Saturated_Fats_Density\",\n",
        "            \"Monounsaturated Fats\": \"Monounsaturated_Fats_Density\",\n",
        "            \"Polyunsaturated Fats\": \"Polyunsaturated_Fats_Density\",\n",
        "            \"Carbohydrates\": \"Carbohydrates_Density\",\n",
        "            \"Sugars\": \"Sugars_Density\",\n",
        "            \"Protein\": \"Protein_Density\",\n",
        "            \"Dietary Fiber\": \"Dietary_Fiber_Density\",\n",
        "            \"Cholesterol\": \"Cholesterol_Density\",\n",
        "            \"Sodium\": \"Sodium_Density\",\n",
        "            }\n"
      ],
      "metadata": {
        "id": "rdZYR2rJAb0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardizer Class"
      ],
      "metadata": {
        "id": "THwqA5T1G3fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Standardizer:\n",
        "    def __init__(self):\n",
        "       pass\n",
        "\n",
        "    def standardize(self, df):\n",
        "        df = df.copy()\n",
        "\n",
        "        df = df.fillna(0)\n",
        "        df[\"Caloric Value\"] = df[\"Caloric Value\"].replace(0, 1)\n",
        "\n",
        "        cal = df[\"Caloric Value\"]\n",
        "\n",
        "        for item, item_density in densities.items():\n",
        "            df[item_density] = df[item] / cal\n",
        "\n",
        "        df[\"Total_Vitamin_Density\"] = df[vitaminColumns].sum(axis=1) / cal\n",
        "\n",
        "        df = df.fillna(0)\n",
        "\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "BpQsdCaDAneV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labeler Class"
      ],
      "metadata": {
        "id": "xIqwRDe1HDS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Labels data based off given instructions *criteria\n",
        "class Labeler:\n",
        "    def __init__(self, thresholds : dict):\n",
        "        self.criteria = thresholds\n",
        "\n",
        "\n",
        "    #Take in a dataframe and label it accordingly with unhealthy/healthy according to given criteria.\n",
        "    def label(self, frame: pd.DataFrame) -> pd.DataFrame:\n",
        "        labels = []\n",
        "        scores = []\n",
        "\n",
        "        for row in frame.itertuples(index=False):\n",
        "            #pull features using getattr\n",
        "            fat = getattr(row, \"Fat_Density\", 0)\n",
        "            sat_fat = getattr(row, \"Saturated_Fats_Density\", 0)\n",
        "            mon_fat = getattr(row, \"Monounsaturated_Fats_Density\", 0)\n",
        "            poly_fat = getattr(row, \"Polyunsaturated_Fats_Density\", 0)\n",
        "            carbs = getattr(row, \"Carbohydrates_Density\", 0)\n",
        "            sugars = getattr(row, \"Sugars_Density\", 0)\n",
        "            protein = getattr(row, \"Protein_Density\", 0)\n",
        "            fiber = getattr(row, \"Dietary_Fiber_Density\", 0)\n",
        "            cholesterol = getattr(row, \"Cholesterol_Density\", 0)\n",
        "            sodium = getattr(row, \"Sodium_Density\", 0)\n",
        "            total_vitamin = getattr(row, \"Total_Vitamin_Density\", 0)\n",
        "\n",
        "            vals = [getattr(row,f'food'), fat,sat_fat, mon_fat,poly_fat,carbs,sugars,protein,fiber,cholesterol,sodium, total_vitamin]\n",
        "\n",
        "            res, score = self.test(vals)\n",
        "            if (res):\n",
        "                labels.append(\"Healthy\")\n",
        "            else:\n",
        "                labels.append(\"Unhealthy\")\n",
        "            scores.append(score)\n",
        "\n",
        "        frame['Health_Label'] = labels\n",
        "        frame['Health_Score'] = scores\n",
        "        return frame\n",
        "\n",
        "    def test(self, values) ->  {bool,int}  :\n",
        "        i = 1\n",
        "        score = 0\n",
        "        test_order = [\n",
        "            \"Fat_Density\",\n",
        "            \"Saturated_Fats_Density\",\n",
        "            \"Monounsaturated_Fats_Density\",\n",
        "            \"Polyunsaturated_Fats_Density\",\n",
        "            \"Carbohydrates_Density\",\n",
        "            \"Sugars_Density\",\n",
        "            \"Protein_Density\",\n",
        "            \"Dietary_Fiber_Density\",\n",
        "            \"Cholesterol_Density\",\n",
        "            \"Sodium_Density\",\n",
        "            \"Total_Vitamin_Density\"\n",
        "        ]\n",
        "\n",
        "        for test in test_order:\n",
        "            v = values[i]\n",
        "            thresh = self.criteria[test]\n",
        "            op = thresh[0]\n",
        "            val = thresh[1]\n",
        "\n",
        "            if op == '<':\n",
        "                if (v < val):\n",
        "                    score += thresh[2]\n",
        "                else:\n",
        "                    score -= thresh[3]\n",
        "            elif op == '>':\n",
        "                if (v > val):\n",
        "                    score += thresh[2]\n",
        "                else:\n",
        "                    score -= thresh[3]\n",
        "\n",
        "            i+=1\n",
        "\n",
        "        res = score >= 3\n",
        "        return res,score\n"
      ],
      "metadata": {
        "id": "d0xiCKHFAg_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# k-NN Class"
      ],
      "metadata": {
        "id": "mkajN1UbHIj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#WRAPPER CLASS FOR KNN MODEL\n",
        "class KNN:\n",
        "    def __init__(self, k):\n",
        "        \"\"\"Constructor to initialize the model.\"\"\"\n",
        "        self.k = k\n",
        "        self.model = KNeighborsClassifier(n_neighbors = k)\n",
        "\n",
        "\n",
        "    def train(self,features, ftargets):\n",
        "        \"\"\"\n",
        "        Trains the model\n",
        "        :param features: The feature data that the model will be trained on.\n",
        "        :param target_train: The target data that the model will be trained on.\n",
        "        :return: The trainined model\n",
        "        \"\"\"\n",
        "        self.model.fit(features,ftargets)\n",
        "\n",
        "\n",
        "    def predict(self, xtest):\n",
        "        \"\"\"\n",
        "        Creates the predictions based on the trained model.\n",
        "        :param xtest: The feature data that will be fed into the model to create the predictions.\n",
        "        :return: The predictions created by the model.\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(xtest)\n",
        "        return predictions\n",
        "\n",
        "    def performance_metrics(self, ytest, predictions):\n",
        "        \"\"\"\n",
        "        Calculates the performance metrics based on the model's predictions.\n",
        "        :param ytest: The correct values.\n",
        "        :param predictions: The predictions created by the model.\n",
        "        :return: accuracy score, f1 score, precision score, and recall score\n",
        "        \"\"\"\n",
        "        return (accuracy_score(ytest, predictions),\n",
        "                f1_score(ytest, predictions, pos_label=\"Healthy\"),\n",
        "                precision_score(ytest, predictions, pos_label=\"Healthy\"),\n",
        "                recall_score(ytest, predictions, pos_label=\"Healthy\"))\n",
        "\n",
        "    def confusion_matrix(self, ytest, predictions):\n",
        "        \"\"\"\n",
        "        Calculates the confusion matrix based on the model's predictions. Prints a basic\n",
        "        confusion matrix to the terminal and also creates a pretty display of the confusion\n",
        "        matrix using matplotlib.\n",
        "        :param ytest: The correct values.\n",
        "        :param predictions: The predictions created by the model.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        cm = confusion_matrix(ytest, predictions, labels=[\"Unhealthy\", \"Healthy\"])\n",
        "        print(f\"Confusion Matrix:\\n {cm}\")\n",
        "        cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Unhealthy\", \"Healthy\"])\n",
        "        cm_disp.plot()\n",
        "        plt.title(\"k-NN\")\n",
        "        plt.show()\n",
        "\n",
        "    def roc_curve(self, xtest, ytest):\n",
        "        \"\"\"\n",
        "        Calculates and plots the ROC curve.\n",
        "        :param xtest: The feature data that corresponds to the correct target values,\n",
        "        used to get the predicted probabilities.\n",
        "        :param ytest: The correct values.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # Get predicted probabilities for positive class\n",
        "        y_probabilities = self.model.predict_proba(xtest)\n",
        "        y_probabilities = y_probabilities[:, 0]\n",
        "\n",
        "        RocCurveDisplay.from_predictions(ytest, y_probabilities, pos_label=\"Healthy\")\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "        plt.title(\"k-NN\")\n",
        "        plt.show()\n",
        "\n",
        "    def blank_cpy(self):\n",
        "        return KNN(self.k)"
      ],
      "metadata": {
        "id": "PLQYmC2YAwkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#WRAPPER CLASS FOR NN\n",
        "class NN:\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructor to initialize the model.\"\"\"\n",
        "        self.model = MLPClassifier(hidden_layer_sizes=(10,10,10,10), activation = 'relu', solver='adam', max_iter=2000,random_state=42)\n",
        "\n",
        "    def train(self,features,target_train):\n",
        "        \"\"\"\n",
        "        Trains the model\n",
        "        :param features: The feature data that the model will be trained on.\n",
        "        :param target_train: The target data that the model will be trained on.\n",
        "        :return: The trainined model\n",
        "        \"\"\"\n",
        "        self.model.fit(features, target_train)\n",
        "        return self.model\n",
        "\n",
        "\n",
        "    def predict(self, xtest):\n",
        "        \"\"\"\n",
        "        Creates the predictions based on the trained model.\n",
        "        :param xtest: The feature data that will be fed into the model to create the predictions.\n",
        "        :return: The predictions created by the model.\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(xtest)\n",
        "        return predictions\n",
        "\n",
        "    def performance_metrics(self, ytest, predictions):\n",
        "        \"\"\"\n",
        "        Calculates the performance metrics based on the model's predictions.\n",
        "        :param ytest: The correct values.\n",
        "        :param predictions: The predictions created by the model.\n",
        "        :return: accuracy score, f1 score, precision score, and recall score\n",
        "        \"\"\"\n",
        "        return (accuracy_score(ytest, predictions),\n",
        "                f1_score(ytest, predictions, pos_label=\"Healthy\"),\n",
        "                precision_score(ytest, predictions, pos_label=\"Healthy\"),\n",
        "                recall_score(ytest, predictions, pos_label=\"Healthy\"))\n",
        "\n",
        "    def confusion_matrix(self, ytest, predictions):\n",
        "        \"\"\"\n",
        "        Calculates the confusion matrix based on the model's predictions. Prints a basic\n",
        "        confusion matrix to the terminal and also creates a pretty display of the confusion\n",
        "        matrix using matplotlib.\n",
        "        :param ytest: The correct values.\n",
        "        :param predictions: The predictions created by the model.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        cm = confusion_matrix(ytest, predictions, labels=[\"Unhealthy\", \"Healthy\"])\n",
        "        print(f\"Confusion Matrix:\\n {cm}\")\n",
        "        cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Unhealthy\", \"Healthy\"])\n",
        "        cm_disp.plot()\n",
        "        plt.title(\"Neural Network\")\n",
        "        plt.show()\n",
        "\n",
        "    def roc_curve(self, xtest, ytest):\n",
        "        \"\"\"\n",
        "        Calculates and plots the ROC curve.\n",
        "        :param xtest: The feature data that corresponds to the correct target values,\n",
        "        used to get the predicted probabilities.\n",
        "        :param ytest: The correct values.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # Get predicted probabilities for positive class\n",
        "        y_probabilities = self.model.predict_proba(xtest)\n",
        "        y_probabilities = y_probabilities[:, 0]\n",
        "\n",
        "        RocCurveDisplay.from_predictions(ytest, y_probabilities, pos_label=\"Healthy\")\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "        plt.title(\"Neural Network\")\n",
        "        plt.show()\n",
        "\n",
        "    def blank_cpy(self):\n",
        "        return NN()\n"
      ],
      "metadata": {
        "id": "9BvTCD0aA9wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RF:\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructor to initialize the model.\"\"\"\n",
        "        self.model = RandomForestClassifier(n_estimators=60, max_depth=None, random_state=42) #Maybe we need tro switch the n estimators here.\n",
        "\n",
        "    def train(self, xtrain, ytrain):\n",
        "        \"\"\"\n",
        "        Trains the model\n",
        "        :param features: The feature data that the model will be trained on.\n",
        "        :param target_train: The target data that the model will be trained on.\n",
        "        :return: The trainined model\n",
        "        \"\"\"\n",
        "        self.model.fit(xtrain, ytrain)\n",
        "\n",
        "    def predict(self, xtest):\n",
        "        \"\"\"\n",
        "        Creates the predictions based on the trained model.\n",
        "        :param xtest: The feature data that will be fed into the model to create the predictions.\n",
        "        :return: The predictions created by the model.\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(xtest)\n",
        "        return predictions\n",
        "\n",
        "    def performance_metrics(self, ytest, predictions):\n",
        "        \"\"\"\n",
        "        Calculates the performance metrics based on the model's predictions.\n",
        "        :param ytest: The correct values.\n",
        "        :param predictions: The predictions created by the model.\n",
        "        :return: accuracy score, f1 score, precision score, and recall score\n",
        "        \"\"\"\n",
        "        return (accuracy_score(ytest, predictions),\n",
        "                f1_score(ytest, predictions, pos_label=\"Healthy\"),\n",
        "                precision_score(ytest, predictions, pos_label=\"Healthy\"),\n",
        "                recall_score(ytest, predictions, pos_label=\"Healthy\"))\n",
        "\n",
        "    def confusion_matrix(self, ytest, predictions):\n",
        "        \"\"\"\n",
        "        Calculates the confusion matrix based on the model's predictions. Prints a basic\n",
        "        confusion matrix to the terminal and also creates a pretty display of the confusion\n",
        "        matrix using matplotlib.\n",
        "        :param ytest: The correct values.\n",
        "        :param predictions: The predictions created by the model.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        cm = confusion_matrix(ytest, predictions, labels=[\"Unhealthy\", \"Healthy\"])\n",
        "        print(f\"Confusion Matrix:\\n {cm}\")\n",
        "        cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Unhealthy\", \"Healthy\"])\n",
        "        cm_disp.plot()\n",
        "        plt.title(\"Random Forest\")\n",
        "        plt.show()\n",
        "\n",
        "    def roc_curve(self, xtest, ytest):\n",
        "        \"\"\"\n",
        "        Calculates and plots the ROC curve.\n",
        "        :param xtest: The feature data that corresponds to the correct target values,\n",
        "        used to get the predicted probabilities.\n",
        "        :param ytest: The correct values.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # Get predicted probabilities for positive class\n",
        "        y_probabilities = self.model.predict_proba(xtest)\n",
        "        y_probabilities = y_probabilities[:, 0]\n",
        "\n",
        "        # Create ROC curve\n",
        "        RocCurveDisplay.from_predictions(ytest, y_probabilities, pos_label=\"Healthy\")\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "        plt.title(\"Random Forest\")\n",
        "        plt.show()\n",
        "\n",
        "    def blank_cpy(self):\n",
        "        return RF()"
      ],
      "metadata": {
        "id": "hEqsi_aRBD2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def KFoldCV(name_of_model, m, features, target, k):\n",
        "    \"\"\"K-Fold Cross Validation for each model. \"\"\"\n",
        "\n",
        "    print(f\"====Starting Cross Validation for {name_of_model}====\")\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "    for train, test in kfold.split(features):\n",
        "        metrics = []\n",
        "        xtrain, xtest = features.iloc[train], features.iloc[test]\n",
        "        ytrain, ytest = target.iloc[train], target.iloc[test]\n",
        "        model = m.blank_cpy()\n",
        "        model.train(xtrain, ytrain)\n",
        "        yhat = model.predict(xtest)\n",
        "        accuracy_NN, f1_NN, precision_NN, recall_NN = model.performance_metrics(ytest, yhat)\n",
        "        metrics.append(f\"{accuracy_NN:.8f}\")\n",
        "        metrics.append(f\"{f1_NN:.8f}\")\n",
        "        metrics.append(f\"{precision_NN:.8f}\")\n",
        "        metrics.append(f\"{recall_NN:.8f}\")\n",
        "        scores.append(metrics)\n",
        "\n",
        "\n",
        "\n",
        "    KFoldRes(name_of_model, scores)\n",
        "\n",
        "def KFoldRes(name_of_model, KFScores):\n",
        "    i = 1\n",
        "    print(\"Fold #:           Accuracy       F1            Precision       Recall\")\n",
        "    for score in KFScores:\n",
        "        print(f\"Fold{i}: Metrics = {score}\")\n",
        "        i+=1\n",
        "    print(\"========================================\\n\")"
      ],
      "metadata": {
        "id": "5Jklqn94BI9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrapEval(name_of_model, m, features, target, iterations):\n",
        "    \"\"\"Bootstrapping procedure for each model.\"\"\"\n",
        "\n",
        "    print(f\"Starting Bootstrap Evaluations for {name_of_model}\")\n",
        "    BSscores = []\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "        #grab bootstrap samples\n",
        "        BSFeatures, BSTargets = resample(features, target, replace = True)\n",
        "\n",
        "        OOB = ~features.index.isin(BSFeatures.index)\n",
        "        OOBFeatures = features[OOB]\n",
        "        OOBTargets = target[OOB]\n",
        "\n",
        "        if len(OOB) == 0:\n",
        "            continue\n",
        "        model = m.blank_cpy()\n",
        "        model.train(BSFeatures, BSTargets)\n",
        "\n",
        "        yhat = model.predict(OOBFeatures)\n",
        "\n",
        "        BSscores.append(accuracy_score(OOBTargets, yhat))\n",
        "\n",
        "    bootstrapRes(name_of_model, BSscores)\n",
        "\n",
        "def bootstrapRes(name_of_model, BSscores):\n",
        "    scores = np.array(BSscores)\n",
        "\n",
        "    mean = scores.mean()\n",
        "    std = scores.std()\n",
        "    ci_lower = np.percentile(scores, 2.5)\n",
        "    ci_upper = np.percentile(scores, 97.5)\n",
        "    median = np.median(scores)\n",
        "    iqr = np.percentile(scores, 75) - np.percentile(scores, 25)\n",
        "\n",
        "    print(f\"\\n====Bootstrap Evaluation {name_of_model}====\")\n",
        "    print(f\"Mean Accuracy:        {mean:.8f}\")\n",
        "    print(f\"Std Deviation:        {std:.8f}\")\n",
        "    print(f\"95% CI:               [{ci_lower:.8f}, {ci_upper:.8f}]\")\n",
        "    print(f\"Median:               {median:.8f}\")\n",
        "    print(f\"IQR:                  {iqr:.8f}\")\n",
        "    print(\"========================================\\n\")\n"
      ],
      "metadata": {
        "id": "8nFiR2SgBN84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Driver code to create, train, and evaluate the 3 models.\"\"\"\n",
        "\n",
        "    # Reads in the datasets from all 5 files\n",
        "    # Assumes the directory of current directory -> Files -> FOOD-DATA-GROUP{1,2,3,4,5}.csv\n",
        "    df1 = pd.read_csv(\"Files/FOOD-DATA-GROUP1.csv\")\n",
        "    df2 = pd.read_csv(\"Files/FOOD-DATA-GROUP2.csv\")\n",
        "    df3 = pd.read_csv(\"Files/FOOD-DATA-GROUP3.csv\")\n",
        "    df4 = pd.read_csv(\"Files/FOOD-DATA-GROUP4.csv\")\n",
        "    df5 = pd.read_csv(\"Files/FOOD-DATA-GROUP5.csv\")\n",
        "\n",
        "    # Combines the 5 DataFrames into a single DataFrame\n",
        "    df = pd.concat([df1,df2,df3,df4,df5], ignore_index=True)\n",
        "\n",
        "    # Uses standardizer to convert all nutritional values to densities\n",
        "    std = Standardizer()\n",
        "    df = std.standardize(df)\n",
        "\n",
        "    # Uses Labeler to label each food as healthy or unhealthy\n",
        "    # These labels will be used as the ground truth values for our models to compare to\n",
        "    L = Labeler(thresholds)\n",
        "    df = L.label(df)\n",
        "\n",
        "    # Pull out features and target\n",
        "    features = df[FEATURE_NAMES]\n",
        "    target = df[\"Health_Label\"]\n",
        "\n",
        "    # Split data into training set and testing set\n",
        "    xtrain, xtest, ytrain, ytest = train_test_split(\n",
        "        features, target,\n",
        "        train_size=0.7,\n",
        "        test_size=0.3,\n",
        "        stratify=target, #get binary classification split\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Scales the features using StandardScaler\n",
        "    # Encoding not required because of model design\n",
        "    scaler = StandardScaler()\n",
        "    xtrain = scaler.fit_transform(xtrain)\n",
        "    xtest = scaler.transform(xtest)\n",
        "\n",
        "    # Creating the models we're testing\n",
        "    Model1 = NN() # Neural network\n",
        "    Model2 = KNN(k=7) # k-NN\n",
        "    Model3 = RF() # Random forest\n",
        "\n",
        "    # Training the models\n",
        "    Model1.train(xtrain, ytrain)\n",
        "    Model2.train(xtrain, ytrain)\n",
        "    Model3.train(xtrain, ytrain)\n",
        "\n",
        "    print(\"Training models:\")\n",
        "\n",
        "    # Evaluating each model's performance\n",
        "    # Neural network metrics\n",
        "    predictionsNN = Model1.predict(xtest)\n",
        "    accuracy_NN, f1_NN, precision_NN, recall_NN = Model1.performance_metrics(ytest, predictionsNN)\n",
        "    print(\"\\n=== Neural Network===\")\n",
        "    print(f\"Accuracy: {accuracy_NN}\")\n",
        "    print(f\"F1 score: {f1_NN}\")\n",
        "    print(f\"Precision: {precision_NN}\")\n",
        "    print(f\"Recall: {recall_NN}\")\n",
        "    Model1.confusion_matrix(ytest, predictionsNN)\n",
        "    Model1.roc_curve(xtest, ytest)\n",
        "\n",
        "    # k-NN metrics\n",
        "    predictionsKNN = Model2.predict(xtest)\n",
        "    accuracy_KNN, f1_KNN, precision_KNN, recall_KNN = Model2.performance_metrics(ytest, predictionsKNN)\n",
        "    print(\"\\n=== k-NN ===\")\n",
        "    print(f\"Accuracy: {accuracy_KNN}\")\n",
        "    print(f\"F1 score: {f1_KNN}\")\n",
        "    print(f\"Precision: {precision_KNN}\")\n",
        "    print(f\"Recall: {recall_KNN}\")\n",
        "    Model2.confusion_matrix(ytest, predictionsKNN)\n",
        "    Model2.roc_curve(xtest, ytest)\n",
        "\n",
        "    # Random forest metrics\n",
        "    predictionsRF = Model3.predict(xtest)\n",
        "    accuracy_RF, f1_RF, precision_RF, recall_RF = Model3.performance_metrics(ytest, predictionsRF)\n",
        "    print(\"\\n=== Random Forest===\")\n",
        "    print(f\"Accuracy: {accuracy_RF}\")\n",
        "    print(f\"F1 score: {f1_RF}\")\n",
        "    print(f\"Precision: {precision_RF}\")\n",
        "    print(f\"Recall: {recall_RF}\")\n",
        "    Model3.confusion_matrix(ytest, predictionsRF)\n",
        "    Model3.roc_curve(xtest, ytest)\n",
        "\n",
        "\n",
        "    #Use KFold Method Above.\n",
        "    print(\"Cross Validation: \")\n",
        "\n",
        "    KFoldCV(\"Neural Network\", Model1, features, target, 10)\n",
        "    KFoldCV(\"K-Nearest Neighbors\", Model2, features, target, 10)\n",
        "    KFoldCV(\"Random Forest\", Model3, features, target, 10)\n",
        "\n",
        "    #Bootstrap Eval\n",
        "\n",
        "\n",
        "    bootstrapEval(\"Neural Network\", Model1, features, target, 50)\n",
        "    bootstrapEval(\"K-Nearest Neighbors\", Model2, features, target, 50)\n",
        "    bootstrapEval(\"Random Forest\", Model3, features, target, 50)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4lV5I8sNBPDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "qZJB3pOiBZPV",
        "outputId": "a26dea44-74e0-44f9-d97b-ef2bd1e3e955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Files/FOOD-DATA-GROUP1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-451043146.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2210623273.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Reads in the datasets from all 5 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Assumes the directory of current directory -> Files -> FOOD-DATA-GROUP{1,2,3,4,5}.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files/FOOD-DATA-GROUP1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files/FOOD-DATA-GROUP2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files/FOOD-DATA-GROUP3.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Files/FOOD-DATA-GROUP1.csv'"
          ]
        }
      ]
    }
  ]
}